大多数是集群资源有限导致的问题。注意合理分配资源



原则1：首先，保证至少有一个executor可以成功启动，否则，提交的spark应用是无法跑起来的

如何保证？

第一点：--executor-cores <= SPARK_WORKER_CORES(spark-env.sh中设置的参数)，否则会出现资源不足报错



第二点：--executor-memorry <= SPARK_WORKER_MEMORY(spark-env.sh中设置的参数)，否则会出现资源不足报错



第三点：--executor-memory >= 470m





SPARK_WORKER_CORES和SPARK_WORKER_MEMORY在spark MasterWebUI（http://master:8080/）中体现如下图：





一、二两点报错体现如下：

报错在日志中体现如图：



报错在WebUI中体现如图，无任何executor启动：







第三点报错体现如下：

报错在日志中体现如图：



报错在WebUI中体现如图，大致意思为资源不足















原则2：根据SPARK_WORKER_CORES和SPARK_WORKER_MEMORY值，在配置时，尽量平均分配

阅读spark源码，理解资源分配算法



另外，测试发现，SPARK_WORKER_CORES和SPARK_WORKER_MEMORY值，与主机资源不符时，应用也会出错

虽然有executor启动，但应用无法正常计算，还是会报错




参考链接：

https://www.cnblogs.com/likai198981/p/4252453.html

https://blog.csdn.net/Glad_Xiao/article/details/49278345

https://blog.csdn.net/xwc35047/article/details/44572897

